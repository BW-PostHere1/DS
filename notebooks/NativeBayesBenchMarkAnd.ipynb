{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rspct.tsv', 'subreddit_info.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(os.listdir(\"./input\"))\n",
    "\n",
    "# running our benchmark code in this kernel lead to memory errors, so \n",
    "# we do a slightly less memory intensive procedure if this is True, \n",
    "# set this as False if you are running on a computer with a lot of RAM\n",
    "# it should be possible to use less memory in this kernel using generators\n",
    "# rather than storing everything in RAM, but we won't explore that here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "rspct_df = pd.read_csv('./input/rspct.tsv', sep='\\t')\n",
    "info_df  = pd.read_csv('./input/subreddit_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7416711cd382370e78ba5079f465ff1d4c6eac3a"
   },
   "source": [
    "## Basic data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "b9cd6088f16683e066378ea9d35785f6c89af44c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d8knd</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>Remember your command line switches...</td>\n",
       "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58mbft</td>\n",
       "      <td>teenmom</td>\n",
       "      <td>So what was Matt \"addicted\" to?</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6ti6re</td>\n",
       "      <td>ringdoorbell</td>\n",
       "      <td>Not door bell, but floodlight mount height.</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77sxto</td>\n",
       "      <td>intel</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             subreddit  \\\n",
       "0  6d8knd  talesfromtechsupport   \n",
       "1  58mbft               teenmom   \n",
       "2  8f73s7                Harley   \n",
       "3  6ti6re          ringdoorbell   \n",
       "4  77sxto                 intel   \n",
       "\n",
       "                                               title  \\\n",
       "0             Remember your command line switches...   \n",
       "1                    So what was Matt \"addicted\" to?   \n",
       "2                                     No Club Colors   \n",
       "3        Not door bell, but floodlight mount height.   \n",
       "4  Worried about my 8700k small fft/data stress r...   \n",
       "\n",
       "                                            selftext  \n",
       "0  Hi there,  <lb>The usual. Long time lerker, fi...  \n",
       "1  Did he ever say what his addiction was or is h...  \n",
       "2  Funny story. I went to college in Las Vegas. T...  \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...  \n",
       "4  Prime95 (regardless of version) and OCCT both,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rspct_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d2cfcbdd2f7c470c70c73c4bbddb37adc5427a0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>in_data</th>\n",
       "      <th>reason_for_exclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>whatsthatbook</td>\n",
       "      <td>advice/question</td>\n",
       "      <td>book</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>theydidthemath</td>\n",
       "      <td>advice/question</td>\n",
       "      <td>calculations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>datarecovery</td>\n",
       "      <td>advice/question</td>\n",
       "      <td>data recovery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>declutter</td>\n",
       "      <td>advice/question</td>\n",
       "      <td>declutter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>productivity</td>\n",
       "      <td>advice/question</td>\n",
       "      <td>discipline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index       subreddit       category_1     category_2 category_3  \\\n",
       "0        0      0   whatsthatbook  advice/question           book        NaN   \n",
       "1        1     25  theydidthemath  advice/question   calculations        NaN   \n",
       "2        2     26    datarecovery  advice/question  data recovery        NaN   \n",
       "3        3     27       declutter  advice/question      declutter        NaN   \n",
       "4        4     30    productivity  advice/question     discipline        NaN   \n",
       "\n",
       "   in_data reason_for_exclusion  \n",
       "0     True                  NaN  \n",
       "1     True                  NaN  \n",
       "2     True                  NaN  \n",
       "3     True                  NaN  \n",
       "4     True                  NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that info_df has information on subreddits that are not in data, \n",
    "# we filter them out here\n",
    "\n",
    "info_df = info_df[info_df.in_data].reset_index()\n",
    "info_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc2ff266075c990c3df99de54dc84cd4566b8e6a"
   },
   "source": [
    "## Naive Bayes benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c486638ded3da5e05e16482214250bc2dec49748"
   },
   "outputs": [],
   "source": [
    "# we join the title and selftext into one field\n",
    "\n",
    "def join_text(row):\n",
    "        return row['title'] + \" \" + row['selftext']\n",
    "\n",
    "rspct_df['text'] = rspct_df[['title', 'selftext']].apply(join_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "43c34a5b2ceb8b2f13cc66eb94e170a49ad30433"
   },
   "outputs": [],
   "source": [
    "# take the last 20% as a test set - N.B data is already randomly shuffled,\n",
    "# and last 20% is a stratified split (equal proportions of subreddits)\n",
    "\n",
    "train_split_index = int(len(rspct_df) * 0.8)\n",
    "\n",
    "train_df, test_df = rspct_df[:train_split_index], rspct_df[train_split_index:]\n",
    "X_train , X_test  = train_df.text, test_df.text\n",
    "y_train, y_test   = train_df.subreddit, test_df.subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "f04a86c4ed629ef2ff1180dd7a4191c130fbb3b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([920, 931, 161, 827, 669])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label encode y\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_test  = le.transform(y_test)\n",
    "\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27ddcca6c2af541e94133222961a83c11f54208e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this cell will take about 10 minutes to run\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# extract features from text using bag-of-words (single words + bigrams)\n",
    "# use tfidf weighting (helps a little for Naive Bayes in general)\n",
    "# note : you can do better than this by extracting more features, then \n",
    "# doing feature selection, but not enough memory on this kernel!\n",
    "\n",
    "print('this cell will take about 10 minutes to run')\n",
    "\n",
    "NUM_FEATURES = 30000 \n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(max_features = NUM_FEATURES,\n",
    "                                min_df=5,\n",
    "                                ngram_range=(1,2),\n",
    "                                stop_words=None,\n",
    "                                token_pattern='(?u)\\\\b\\\\w+\\\\b',\n",
    "                            )\n",
    "\n",
    "X_train = tf_idf_vectorizer.fit_transform(X_train)\n",
    "X_test  = tf_idf_vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# if we have more memory, select top 100000 features and select good features\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, 30000)\n",
    "\n",
    "chi2_selector.fit(X_train, y_train) \n",
    "\n",
    "X_train = chi2_selector.transform(X_train)\n",
    "X_test  = chi2_selector.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d317a155229fa60c6241e7b8d2355fb1cba9d43"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# train a naive bayes model, get predictions\n",
    "\n",
    "nb_model = MultinomialNB(alpha=0.1)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = nb_model.predict_proba(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d31738daa5d0382761477f16e79d1800ac6f730",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we use precision-at-k metrics to evaluate performance\n",
    "# (https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Precision_at_K)\n",
    "\n",
    "def precision_at_k(y_true, y_pred, k=5):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred = np.argsort(y_pred, axis=1)\n",
    "    y_pred = y_pred[:, ::-1][:, :k]\n",
    "    arr = [y in s for y, s in zip(y_true, y_pred)]\n",
    "    return np.mean(arr)\n",
    "\n",
    "print('precision@1 =', np.mean(y_test == y_pred))\n",
    "print('precision@3 =', precision_at_k(y_test, y_pred_proba, 3))\n",
    "print('precision@5 =', precision_at_k(y_test, y_pred_proba, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "755686e8e4421d8f4a61819bc3c4afa958294779"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'model.sav'\n",
    "pickle.dump(nb_model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pre-Trained Model (Gnews)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Remember your command line switches... Hi ther...\n",
       "1         So what was Matt \"addicted\" to? Did he ever sa...\n",
       "2         No Club Colors Funny story. I went to college ...\n",
       "3         Not door bell, but floodlight mount height. I ...\n",
       "4         Worried about my 8700k small fft/data stress r...\n",
       "                                ...                        \n",
       "810395    Best workflow for app integration Hi all!<lb><...\n",
       "810396    4K editing machine problems i upgraded my gpu ...\n",
       "810397    Advice on mixing and editing I recently attend...\n",
       "810398    How to properly control hue lights? When I say...\n",
       "810399    First Yak? Alright so I've never owned a kayak...\n",
       "Name: text, Length: 810400, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810400     100+ Classrooms..how do you engage the student...\n",
       "810401     [MANGA SPOILERS] Someone I read **Chapter 48: ...\n",
       "810402     [21 y.o][Beard tips/first time] I really need ...\n",
       "810403     Gluing the tip back on and durability of the b...\n",
       "810404     Your examples of makeup that's not \"standard\" ...\n",
       "                                 ...                        \n",
       "1012995    Is this months rebirth and dungeon astro's wor...\n",
       "1012996    I might need a Medical leave from grad school ...\n",
       "1012997    Police harassing ethnic minorities in Hong Kon...\n",
       "1012998    SU EECS 2030 and EECS 2021 - need advice Hi, I...\n",
       "1012999    What is the worse wine you ever had? My worst ...\n",
       "Name: text, Length: 202600, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         talesfromtechsupport\n",
       "1                      teenmom\n",
       "2                       Harley\n",
       "3                 ringdoorbell\n",
       "4                        intel\n",
       "                  ...         \n",
       "810395                     git\n",
       "810396                premiere\n",
       "810397             VoiceActing\n",
       "810398              amazonecho\n",
       "810399                Kayaking\n",
       "Name: subreddit, Length: 810400, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/popkdodge/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Remember your command line switches... Hi ther...\n",
       "1         So what was Matt \"addicted\" to? Did he ever sa...\n",
       "2         No Club Colors Funny story. I went to college ...\n",
       "3         Not door bell, but floodlight mount height. I ...\n",
       "4         Worried about my 8700k small fft/data stress r...\n",
       "                                ...                        \n",
       "810395    Best workflow for app integration Hi all!<lb><...\n",
       "810396    4K editing machine problems i upgraded my gpu ...\n",
       "810397    Advice on mixing and editing I recently attend...\n",
       "810398    How to properly control hue lights? When I say...\n",
       "810399    First Yak? Alright so I've never owned a kayak...\n",
       "Name: text, Length: 810400, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 20), dtype=float32, numpy=\n",
       "array([[ 1.7077502 , -4.0037446 ,  3.7489946 ,  2.948087  , -5.1763754 ,\n",
       "        -4.1330338 , -2.4770722 ,  2.1744409 ,  1.1640458 ,  0.9517227 ,\n",
       "        -3.0390337 ,  1.6589148 ,  0.33850574,  0.599539  , -3.4987762 ,\n",
       "         1.1391282 ,  4.9868565 , -0.91237336, -1.6852969 , -2.0769358 ],\n",
       "       [ 0.922072  , -4.147851  ,  1.5294727 ,  0.8775935 , -3.389209  ,\n",
       "        -3.3807397 , -2.2445643 ,  3.1804943 ,  4.2478952 ,  1.2665141 ,\n",
       "        -1.9726633 ,  0.9127798 ,  0.61721325, -0.15477253, -3.6096973 ,\n",
       "         2.3084846 ,  3.961409  , -1.7416806 , -1.7581972 , -1.2604722 ],\n",
       "       [ 1.6637378 , -2.7635317 ,  2.0233257 ,  1.113759  , -5.7743273 ,\n",
       "        -3.2148895 , -3.460592  ,  1.6691866 ,  1.884025  ,  1.714093  ,\n",
       "        -4.758285  ,  1.7424115 , -0.30933595, -0.2347627 , -5.368443  ,\n",
       "         1.3150398 ,  3.7524164 , -1.8488756 , -3.5905008 , -0.19346792]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(model, output_shape=[20], input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(X_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1013, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=1000,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=stop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 290,  323,  463, ...,  166, 1011, 1000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
