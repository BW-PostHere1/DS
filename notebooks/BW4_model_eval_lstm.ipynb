{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BW4_model_eval_lstm",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n7u9QsWGJyv",
        "colab_type": "text"
      },
      "source": [
        "ref https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocmyCQSLF2eZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b16dae39-c164-40c4-f81c-20a16c388f5b"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVjz1umhEY9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d97e79f5-1770-4dd1-bee2-0a4164bb0b14"
      },
      "source": [
        "\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "nltk.download('stopwords')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sn649JFE53o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/reduced30k.tsv', sep='\\t')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAc0OImEEhBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from numpy import argmax\n",
        "\n",
        "\n",
        "#newdf  = df.sample(frac=.1)\n",
        "newdf = df.copy()\n",
        "newdf['Text'] =newdf['title'].str.cat(newdf['selftext'], sep=' ')\n",
        "newdf = newdf[['subreddit', 'Text']]\n",
        "newdf.columns = ['Class Name', 'Text']\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkaHcknsFDP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e79a05bd-9624-464c-c644-79873b30e533"
      },
      "source": [
        "#need convert the labels to numeric\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(newdf['Class Name'])\n",
        "print(integer_encoded, len(label_encoder.classes_))   \n",
        "       \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[164 107 657 ... 802 339 421] 1013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdpuA_guFTN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e94ff387-04e5-4d7e-9165-f665468c843b"
      },
      "source": [
        "\n",
        "training_portion = .8\n",
        "train_size = int(newdf.shape[0] * training_portion)\n",
        "\n",
        "train,test = newdf[0: train_size],newdf[train_size:]\n",
        "print(train.shape,test.shape)\n",
        "\n",
        "test.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(243120, 2) (60780, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Name</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>243120</th>\n",
              "      <td>learnmachinelearning</td>\n",
              "      <td>Starting an image recognition network? Hey all...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243121</th>\n",
              "      <td>GenderCritical</td>\n",
              "      <td>Women = infants I’m sure someone has covered t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243122</th>\n",
              "      <td>PlasticSurgery</td>\n",
              "      <td>I am getting a rhinoplasty to fix breathing af...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243123</th>\n",
              "      <td>DebateAltRight</td>\n",
              "      <td>\"Open borders, but only for white countries\" S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243124</th>\n",
              "      <td>pihole</td>\n",
              "      <td>Web Interface (Lighttpd) stops working Some mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Class Name                                               Text\n",
              "243120  learnmachinelearning  Starting an image recognition network? Hey all...\n",
              "243121        GenderCritical  Women = infants I’m sure someone has covered t...\n",
              "243122        PlasticSurgery  I am getting a rhinoplasty to fix breathing af...\n",
              "243123        DebateAltRight  \"Open borders, but only for white countries\" S...\n",
              "243124                pihole  Web Interface (Lighttpd) stops working Some mo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3l2MXZuHbWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "#vocab_size = 5000\n",
        "embedding_dim = 13\n",
        "max_length = 200\n",
        "trunc_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "train_texts = train['Text'].tolist()\n",
        "test_texts = test['Text'].tolist()\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_texts)   #for train, \n",
        "\n",
        "word_index = tokenizer.word_index  \n",
        "\n",
        "X_train_sequences = tokenizer.texts_to_sequences(train_texts)     # sequences is a list of seq\n",
        "X_train_padded = pad_sequences(X_train_sequences,maxlen=max_length, truncating=trunc_type)  #training X\n",
        "\n",
        "##\n",
        "X_test_sequences = tokenizer.texts_to_sequences(test_texts)     #testing X\n",
        "X_test_padded = pad_sequences(X_test_sequences,maxlen=max_length)            #X_test_padded\n",
        "\n",
        "\n",
        "train_y = train['Class Name'].tolist()\n",
        "test_y = test['Class Name'].tolist()\n",
        "\n",
        "# transform labels into int\n",
        "le  = LabelEncoder()\n",
        "le.fit(newdf['Class Name'])\n",
        "\n",
        "\n",
        "train_y = le.transform(train_y)\n",
        "test_y = le.transform(test_y)\n",
        "train_y = tf.keras.utils.to_categorical(train_y)    # https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
        "test_y = tf.keras.utils.to_categorical(test_y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM6Meuv6AU6A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebd66791-8ff0-426c-e2d9-80864a7bfac9"
      },
      "source": [
        "len(train_y) , len(X_train_sequences)\n",
        "\n",
        "len(word_index)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "424272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13DLRsw2HjCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "964208bb-c623-4cb5-bc75-e3f1ab7818ed"
      },
      "source": [
        "\n",
        "woahvicky = EarlyStopping(patience=4, restore_best_weights=True)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "    tf.keras.layers.Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "#    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.LSTM(100, dropout=0.2),\n",
        "    tf.keras.layers.Dense(1013, activation='softmax')   ## this matches the number of categories\n",
        "    ])\n",
        "\n",
        "model.summary()\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
        "\n",
        "NUM_EPOCHS = 1000\n",
        "\n",
        "history = model.fit(X_train_padded,train_y,\n",
        "                    batch_size=32, \n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    validation_data=(X_test_padded,test_y),\n",
        "                    callbacks= woahvicky)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 13)          130000    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, None, 128)         8448      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               91600     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1013)              102313    \n",
            "=================================================================\n",
            "Total params: 332,361\n",
            "Trainable params: 332,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "7598/7598 [==============================] - 78s 10ms/step - loss: 6.7371 - accuracy: 0.0029 - val_loss: 6.5215 - val_accuracy: 0.0055\n",
            "Epoch 2/1000\n",
            "7598/7598 [==============================] - 78s 10ms/step - loss: 6.1757 - accuracy: 0.0098 - val_loss: 5.7915 - val_accuracy: 0.0151\n",
            "Epoch 3/1000\n",
            "7598/7598 [==============================] - 77s 10ms/step - loss: 5.4083 - accuracy: 0.0331 - val_loss: 5.1473 - val_accuracy: 0.0540\n",
            "Epoch 4/1000\n",
            "7598/7598 [==============================] - 76s 10ms/step - loss: 4.7938 - accuracy: 0.0936 - val_loss: 4.5354 - val_accuracy: 0.1340\n",
            "Epoch 5/1000\n",
            "7598/7598 [==============================] - 78s 10ms/step - loss: 4.3182 - accuracy: 0.1755 - val_loss: 4.2392 - val_accuracy: 0.2061\n",
            "Epoch 6/1000\n",
            "7598/7598 [==============================] - 80s 10ms/step - loss: 3.9897 - accuracy: 0.2444 - val_loss: 3.9341 - val_accuracy: 0.2664\n",
            "Epoch 7/1000\n",
            "7597/7598 [============================>.] - ETA: 0s - loss: 3.7324 - accuracy: 0.2972"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKfKxJANIFOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\n",
        "    'cnn_model1.h5', overwrite=True, include_optimizer=True, save_format=None,\n",
        "    signatures=None, options=None\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZfrFCT3HohD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}